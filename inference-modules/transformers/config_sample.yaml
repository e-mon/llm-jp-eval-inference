run_name: null  # This value will be applied to both offline_inference.run_name and wandb.run_name with the highest priority.

wandb:
  launch: false
  entity: entity
  project: project

tokenize_kwargs:
  add_special_tokens: true

model:
  pretrained_model_name_or_path: llm-jp/llm-jp-3-3.7b-instruct

tokenizer:
  pretrained_model_name_or_path: llm-jp/llm-jp-3-3.7b-instruct

prompt_json_path: '../../../local_files/datasets/2.0.0/evaluation/path/to/prompts/*.eval-prompt.json'
